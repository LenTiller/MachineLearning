{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a)\n",
    "<img src =\"ML_gradedAssignemtn2_part2_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)\n",
    "The logistic regression with quadratic terms seems intuitively to be the best estimator. It has a good recall value and generalises well. while the decision boundary has a good recall value to, the point of class 0 (+) in the upper right corner has a strong influence on the dicision boundary and thus impedes a good generalisation of the estimator. \n",
    "\n",
    "One possibility to use ones intuition is to feed a new instance to all estimator functions simultaneously. Every estimator then would give a certain output. Each output could then be mapped to a certain value f. The mapping function should reflect ones intuition, meaning that it weights values of intuitively better estimators heavier than others. \n",
    "\n",
    "For categorical data, we could for example assigne a weight to every class. We than add up all weighs of similarly predicted classes. The class with the highest weights is the prediction of the estimator-cluster.\n",
    "\n",
    "For descrete values it is  possible to use an average or a similar value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
